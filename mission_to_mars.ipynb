{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "# * Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "# Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Engineers Dream Big with Small Spacecraft\n",
      "The first CubeSat mission to deep space will launch in May.\n"
     ]
    }
   ],
   "source": [
    "# * Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "# news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "# ```\n",
    "\n",
    "scraped_data = []\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless = False)\n",
    "nasa_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(nasa_url)\n",
    "time.sleep(10)\n",
    "nasa_html = browser.html\n",
    "nasa_soup = BeautifulSoup(nasa_html, 'html.parser')\n",
    "headlines = nasa_soup.find_all('div', class_='content_title')\n",
    "news_title = headlines[0].find('a').text\n",
    "paragraph = nasa_soup.find_all('div', class_=\"article_teaser_body\")\n",
    "news_p = paragraph[0].text\n",
    "print (news_title)\n",
    "print (news_p)\n",
    "latest_news = {\"latest_news\": {\"news_title\": news_title, \"news_paragraph\": news_p}}\n",
    "scraped_data.append(latest_news)\n",
    "# print (scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov//spaceimages/images/wallpaper/PIA19639-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# * Visit the url for JPL's Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "# * Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "# * Make sure to find the image url to the full size `.jpg` image.\n",
    "# * Make sure to save a complete url string for this image.\n",
    "# featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "jpl_html = requests.get(jpl_url)\n",
    "jpl_soup = BeautifulSoup(jpl_html.content, 'html.parser')\n",
    "jpl_image = jpl_soup.find('article', class_='carousel_item').get(\"style\")\n",
    "jpl_image_url = jpl_image.replace(\"background-image: url('\", \"https://www.jpl.nasa.gov/\")\n",
    "featured_image_url = jpl_image_url.replace(\"');\",\"\")\n",
    "print (featured_image_url)\n",
    "featured_image_dict = {\"featured_image\": featured_image_url}\n",
    "scraped_data.append(featured_image_dict)\n",
    "# print(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2026 (April 18, 2018), Sunny, high -6C/21F, low -73C/-99F, pressure at 7.19 hPa, daylight 05:26-17:21\n"
     ]
    }
   ],
   "source": [
    "# ### Mars Weather\n",
    "# * Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "# mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n",
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless = False)\n",
    "twitter_url = \"https://twitter.com/marswxreport\"\n",
    "twitter_html = requests.get(twitter_url)\n",
    "twitter_soup = BeautifulSoup(twitter_html.content, 'html.parser')\n",
    "tweets = twitter_soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "mars_weather = tweets[0].text\n",
    "print (mars_weather)\n",
    "weather_dict = {\"weather\": mars_weather}\n",
    "scraped_data.append(weather_dict)\n",
    "# print(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter</th>\n",
       "      <td>6,792 km\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter</th>\n",
       "      <td>6,752 km\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass</th>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance</th>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period</th>\n",
       "      <td>687 days (1.9 years)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature</th>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               fact\n",
       "description                                        \n",
       "Equatorial Diameter                      6,792 km\\n\n",
       "Polar Diameter                           6,752 km\\n\n",
       "Mass                  6.42 x 10^23 kg (10.7% Earth)\n",
       "Moons                           2 (Phobos & Deimos)\n",
       "Orbit Distance             227,943,824 km (1.52 AU)\n",
       "Orbit Period                 687 days (1.9 years)\\n\n",
       "Surface Temperature                   -153 to 20 °C\n",
       "First Record                      2nd millennium BC\n",
       "Recorded By                    Egyptian astronomers"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### Mars Facts\n",
    "# * Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "# * Use Pandas to convert the data to a HTML table string.\n",
    "fact_url = \"http://space-facts.com/mars/\"\n",
    "fact_html = requests.get(fact_url)\n",
    "fact_soup = BeautifulSoup(fact_html.content, 'html.parser')\n",
    "fact_category = fact_soup.find_all(\"td\", class_=\"column-1\")\n",
    "fact_actual = fact_soup.find_all(\"td\", class_=\"column-2\")\n",
    "# print (fact_category)\n",
    "# print (fact_actual)\n",
    "category_list = []\n",
    "for category in fact_category:\n",
    "    c = category.text\n",
    "    c = c.replace(\":\",\"\")\n",
    "    category_list.append(c)\n",
    "# print (category_list)\n",
    "fact_list = []\n",
    "for fact in fact_actual:\n",
    "    f = fact.text\n",
    "    fact_list.append(f)\n",
    "# print (fact_list)\n",
    "mars_df = pd.DataFrame({\"description\": category_list, \"fact\":fact_list})\n",
    "mars_df = mars_df.set_index('description')\n",
    "mars_facts = mars_df.to_dict()\n",
    "scraped_data.append(mars_facts)\n",
    "mars_df\n",
    "# print(scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Valles Marineris Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# ### Mars Hemisperes\n",
    "\n",
    "# * Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "# * Save both the image url string for the full resolution hemipshere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "# * Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# ```python\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n",
    "\n",
    "astro_base = \"https://astrogeology.usgs.gov\"\n",
    "hemisphere_search = \"/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "h_url = astro_base + hemisphere_search\n",
    "h_html = requests.get(h_url)\n",
    "h_soup = BeautifulSoup(h_html.content, 'html.parser')\n",
    "h_a = h_soup.find_all(\"a\", class_=\"itemLink product-item\")\n",
    "# print (h_a)\n",
    "links = []\n",
    "for a in h_a:\n",
    "    h_href = a['href']\n",
    "    hemisphere_url = astro_base + h_href\n",
    "    links.append(hemisphere_url)\n",
    "# print (links)\n",
    "hemisphere_dictionary = []\n",
    "h_name = []\n",
    "h_img = []\n",
    "h_list = []\n",
    "for z in np.arange(len(links)):\n",
    "    l_html = requests.get(links[z])\n",
    "    l_soup = BeautifulSoup(l_html.content, 'html.parser')\n",
    "    l_li = l_soup.find_all(\"a\")\n",
    "    for aa in l_li:\n",
    "        aa_href = aa.get('href')\n",
    "        if aa_href[-3:] == \"jpg\":\n",
    "            h_jpg = aa_href\n",
    "    l_heading = l_soup.find(\"h2\", class_ = \"title\")\n",
    "    name = l_heading.text\n",
    "    name = name.replace(\" Enhanced\",\"\")\n",
    "    h_name.append(name)\n",
    "    h_img.append(h_jpg)\n",
    "    hemisphere_dict = {'title': name, 'img_url': h_jpg}\n",
    "    hemisphere_dictionary.append(hemisphere_dict)\n",
    "h_df = pd.DataFrame({'title': h_name, 'img_url': h_img})\n",
    "h_df = h_df.set_index('title')\n",
    "h_dict = h_df.to_dict()\n",
    "print (hemisphere_dict)\n",
    "scraped_data.append(h_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   {\n",
      "      \"latest_news\": {\n",
      "         \"news_title\": \"NASA Engineers Dream Big with Small Spacecraft\",\n",
      "         \"news_paragraph\": \"The first CubeSat mission to deep space will launch in May.\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"featured_image\": \"https://www.jpl.nasa.gov//spaceimages/images/wallpaper/PIA19639-1920x1200.jpg\"\n",
      "   },\n",
      "   {\n",
      "      \"weather\": \"Sol 2026 (April 18, 2018), Sunny, high -6C/21F, low -73C/-99F, pressure at 7.19 hPa, daylight 05:26-17:21\"\n",
      "   },\n",
      "   {\n",
      "      \"fact\": {\n",
      "         \"Equatorial Diameter\": \"6,792 km\\n\",\n",
      "         \"Polar Diameter\": \"6,752 km\\n\",\n",
      "         \"Mass\": \"6.42 x 10^23 kg (10.7% Earth)\",\n",
      "         \"Moons\": \"2 (Phobos & Deimos)\",\n",
      "         \"Orbit Distance\": \"227,943,824 km (1.52 AU)\",\n",
      "         \"Orbit Period\": \"687 days (1.9 years)\\n\",\n",
      "         \"Surface Temperature \": \"-153 to 20 \\u00b0C\",\n",
      "         \"First Record\": \"2nd millennium BC\",\n",
      "         \"Recorded By\": \"Egyptian astronomers\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"img_url\": {\n",
      "         \"Cerberus Hemisphere\": \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\",\n",
      "         \"Schiaparelli Hemisphere\": \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\",\n",
      "         \"Syrtis Major Hemisphere\": \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\",\n",
      "         \"Valles Marineris Hemisphere\": \"http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\"\n",
      "      }\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print (json.dumps(scraped_data, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata]",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
